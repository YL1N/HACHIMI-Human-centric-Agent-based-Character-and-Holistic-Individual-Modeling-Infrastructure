# -*- coding: utf-8 -*-
"""
app.py â€” å¤šæ™ºèƒ½ä½“ Â· å®æ—¶å¤šè½®åä½œ Â· å­¦ç”Ÿç”»åƒæ‰¹é‡ç”Ÿæˆï¼ˆå…¨éƒ¨å­—æ®µç”±æ™ºèƒ½ä½“ç»APIäº§å‡ºï¼‰
åœ¨çº¿å‰ç½®æ§åˆ¶ï¼šé…é¢åˆ†æ¡¶è°ƒåº¦ + è½»é‡è¿‡æ»¤ + è‡ªç›¸ä¼¼åº¦é˜ˆï¼ˆSimHashï¼‰
åç«¯ï¼šOrchestrator + 5 å†…å®¹Agent + Validatorï¼Œç™½æ¿é»‘æ¿æ¨¡å¼ + å¤šè½®åå•†
ä¾èµ–ï¼šstreamlit, requests
æ¥å£ï¼šä½¿ç”¨ AIECNU /v1/chat/completionsï¼ˆå·²ç¡¬ç¼–ç ï¼‰
!!! åŠŸèƒ½è¦ç‚¹ï¼š
1) æ— ç”Ÿæˆä¸Šé™ï¼šæŒ‰ 50 æ¡/ç‰‡ åˆ†ç‰‡ï¼Œæ”¯æŒä»»æ„å¤§ Nï¼›é¡¶æ â€œåˆ†ç‰‡è¿›åº¦â€ï¼Œä¸­éƒ¨â€œå½“å‰ç‰‡è¿›åº¦â€ï¼›
2) æ— åå•†è½®æ•°ä¸Šé™ï¼šè½®æ•° number_inputï¼ˆä¸è®¾ä¸Šé™ï¼‰ï¼›
3) æš‚åœ/ç»§ç»­ï¼šå¯éšæ—¶æš‚åœï¼›æš‚åœå³ä½œåºŸâ€œå½“å‰æ­£åœ¨æ„å»ºâ€çš„æ¡ç›®ï¼›ç»§ç»­è‡ªåŠ¨æ‰¾åˆ°æœ€åä¸€ç‰‡å¹¶ç»­å†™ï¼›
4) è‡ªåŠ¨è½ç›˜ï¼šç”Ÿæˆä¸€æ¡å°±å†™ä¸€æ¡åˆ°æœ¬åœ° `output/<run_id>/students_chunk_{i}.jsonl`ï¼›50æ¡ä¸ºä¸€ç‰‡ï¼Œè‡ªåŠ¨æ¢æ–°æ–‡ä»¶ï¼›
5) ä½“è£æ–°æ ‡å‡†ï¼šä»·å€¼è§‚/åˆ›é€ åŠ›/å¿ƒç†å¥åº· å¼ºåˆ¶â€œå•æ®µè¿ç»­è‡ªç„¶è¯­è¨€â€ï¼›ä¸€è‡´æ€§ä¸åˆè§„æ ¡éªŒï¼›
6) å­¦æœ¯æ°´å¹³ä¸¥æ ¼â€œå››é€‰ä¸€ï¼ˆå›ºå®šæ–‡æ¡ˆï¼‰â€ï¼›
7) æ–°å¢ï¼šQuotaSchedulerï¼ˆå¹´çº§Ã—æ€§åˆ«Ã—ä¼˜åŠ¿å­¦ç§‘ç°‡ï¼‰å‰ç½®é‡‡æ ·ï¼›è½»é‡è¿‡æ»¤ï¼›SimHash å»åŒè´¨åŒ–ï¼›å¤±è´¥æ ·æœ¬è½ç›˜ã€‚
8) æ–°å¢ï¼šğŸ–§ Agent å®æ—¶äº¤äº’æ§åˆ¶å°ï¼ˆPrompt/Output/Issues å¯è§†åŒ–ï¼‰ã€‚
"""

import json, re, random, math, os, glob, time, hashlib
from copy import deepcopy
from typing import Any, Dict, List, Tuple, Optional
import streamlit as st
import requests

# ================== ä½ çš„ APIï¼ˆæŒ‰è¦æ±‚ç¡¬ç¼–ç ï¼‰ ==================
AIECNU_API_KEY = "sk-FXzwhYkmwTgmjinGU5iBwYBhIwLbvLVcKtfwXsfLOkQcQbnm"
AIECNU_BASE_URL = "http://49.51.37.239:3006/v1"
MODEL = "gpt-4.1"
HEADERS = {"Content-Type": "application/json", "Authorization": f"Bearer {AIECNU_API_KEY}"}

CHUNK_SIZE_DEFAULT = 50
MAX_RETRIES_PER_SLOT = 4
SIMHASH_BITS = 64
SIMHASH_HAMMING_THRESHOLD_DEFAULT = 3  # <=3 è§†ä¸ºè¿‡è¿‘ï¼Œé‡é‡‡

LEVEL_SET_STRICT = {
    "é«˜": "é«˜ï¼šæˆç»©å…¨æ ¡æ’åå‰10%",
    "ä¸­": "ä¸­ï¼šæˆç»©å…¨æ ¡æ’åå‰10%è‡³30%",
    "ä½": "ä½ï¼šæˆç»©å…¨æ ¡æ’åå‰30%è‡³50%",
    "å·®": "å·®ï¼šæˆç»©å…¨æ ¡æ’åå50%"
}
STRICT_ALLOWED_STRINGS = set(LEVEL_SET_STRICT.values())

# ä»£ç†åæ ¡éªŒæ­£åˆ™ï¼ˆæ”¯æŒ 2 èŠ‚å§“ / 1-3 èŠ‚åï¼Œæ¯èŠ‚å« 1â€“5 å£°è°ƒæ•°å­—ï¼‰
AGENT_ID_REGEX = r"^(?:[a-z]+[1-5]){1,2}_(?:[a-z]+[1-5]){1,3}$"

GRADES = ["äº”å¹´çº§","å…­å¹´çº§","åˆä¸€","åˆäºŒ","åˆä¸‰","é«˜ä¸€","é«˜äºŒ","é«˜ä¸‰"]
GENDERS = ["ç”·","å¥³"]
SUBJ_CLUSTERS = {
    "ç†ç§‘å‘": ["æ•°å­¦","ç‰©ç†","åŒ–å­¦","ä¿¡æ¯æŠ€æœ¯"],
    "æ–‡ç¤¾å‘": ["è¯­æ–‡","å†å²","æ”¿æ²»","åœ°ç†"],
    "è‰ºä½“å‘": ["ç¾æœ¯","éŸ³ä¹","ä½“è‚²"],
    "å¤–è¯­ç”Ÿç‰©å‘": ["è‹±è¯­","ç”Ÿç‰©"]
}

# ---- streamlit rerun å…¼å®¹å°è£… ----
def _st_rerun():
    try:
        st.rerun()
    except AttributeError:
        st.experimental_rerun()

# ================== LLM è°ƒç”¨ä¸è§£æï¼ˆåŸºç¡€ï¼‰ ==================
def call_llm(messages: List[Dict[str, Any]], max_tokens=900, temperature=0.95) -> str:
    url = f"{AIECNU_BASE_URL.rstrip('/')}/chat/completions"
    payload = {"model": MODEL, "messages": messages, "max_tokens": max_tokens, "temperature": temperature}
    r = requests.post(url, headers=HEADERS, json=payload, timeout=120)
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"]

def try_json(text: str) -> Dict[str, Any]:
    text = text.strip()
    try:
        return json.loads(text)
    except Exception:
        m = re.search(r"\{.*\}", text, flags=re.S)
        if m:
            try:
                return json.loads(m.group(0))
            except:
                return {}
        return {}

def non_empty(v: Any) -> bool:
    if v is None: return False
    if isinstance(v, str): return v.strip() != ""
    if isinstance(v, (list, dict)): return len(v) > 0
    return True

# ================== SimHashï¼ˆå»åŒè´¨åŒ–ï¼‰ ==================
def _text_to_ngrams(t: str, n: int = 3) -> List[str]:
    t = re.sub(r"\s+", "", t)
    return [t[i:i+n] for i in range(max(0, len(t)-n+1))] if t else []

def _simhash64(text: str) -> int:
    v = [0]*SIMHASH_BITS
    for g in _text_to_ngrams(text, 3):
        h = int(hashlib.md5(g.encode("utf-8")).hexdigest(), 16)
        for i in range(SIMHASH_BITS):
            v[i] += 1 if ((h >> i) & 1) else -1
    out = 0
    for i in range(SIMHASH_BITS):
        if v[i] >= 0:
            out |= (1 << i)
    return out

def _hamming(a: int, b: int) -> int:
    x = a ^ b
    cnt = 0
    while x:
        x &= x-1
        cnt += 1
    return cnt

class SimilarityGate:
    def __init__(self, threshold: int = SIMHASH_HAMMING_THRESHOLD_DEFAULT):
        self.threshold = threshold
        self.pool: List[int] = []

    def too_similar(self, text: str) -> bool:
        if not text: return False
        h = _simhash64(text)
        for prev in self.pool:
            if _hamming(h, prev) <= self.threshold:
                return True
        return False

    def accept(self, text: str):
        if not text: return
        self.pool.append(_simhash64(text))

# ================== è½»é‡è¿‡æ»¤ï¼ˆä½“è£/æ­£åˆ™/æ˜¾å¼å‘½ä¸­ï¼‰ ==================
AGENT_PARAGRAPH_FIELDS = ["ä»·å€¼è§‚","åˆ›é€ åŠ›","å¿ƒç†å¥åº·"]

def _is_single_paragraph(s: str) -> bool:
    if not isinstance(s, str): return False
    if re.search(r"(\n\s*\n)|(^\s*[-â€¢\d]+\.)", s): return False
    return True

def _has_any(s: str, kws: List[str]) -> bool:
    return any(kw in s for kw in kws)

def _light_filter(item: Dict[str, Any]) -> Tuple[bool, List[str]]:
    reasons = []
    for k in ["å§“å","å¹´é¾„","æ€§åˆ«","å¹´çº§","äººæ ¼","æ“…é•¿ç§‘ç›®","è–„å¼±ç§‘ç›®","å­¦æœ¯æ°´å¹³","ä»·å€¼è§‚","åˆ›é€ åŠ›","å¿ƒç†å¥åº·","ä»£ç†å","å‘å±•é˜¶æ®µ","ç¤¾äº¤å…³ç³»"]:
        if k not in item or not non_empty(item[k]):
            reasons.append(f"ç¼ºå­—æ®µæˆ–ä¸ºç©ºï¼š{k}")
    if item.get("å­¦æœ¯æ°´å¹³") not in STRICT_ALLOWED_STRINGS:
        reasons.append("å­¦æœ¯æ°´å¹³éå››é€‰ä¸€å›ºå®šæ–‡æ¡ˆ")
    if not re.match(AGENT_ID_REGEX, str(item.get("ä»£ç†å",""))):
        reasons.append("ä»£ç†åä¸åˆè§„ï¼ˆéœ€æ‹¼éŸ³åˆ†èŠ‚+å£°è°ƒæ•°å­—ï¼›å§“1-2èŠ‚ï¼Œå1-3èŠ‚ï¼‰")
    for f in AGENT_PARAGRAPH_FIELDS:
        if not _is_single_paragraph(item.get(f,"")):
            reasons.append(f"{f} éå•æ®µä½“è£")
    val = item.get("ä»·å€¼è§‚","")
    dims7 = ["é“å¾·ä¿®å…»","èº«å¿ƒå¥åº·","æ³•æ²»æ„è¯†","ç¤¾ä¼šè´£ä»»","æ”¿æ²»è®¤åŒ","æ–‡åŒ–ç´ å…»","å®¶åº­è§‚å¿µ"]
    lvl_words = ["é«˜","è¾ƒé«˜","ä¸­","ä¸­ä¸Š","è¾ƒä½","ä½"]
    if not _has_any(val, dims7): reasons.append("ä»·å€¼è§‚æœªè§ä¸ƒç»´æ˜¾å¼åè¯ï¼ˆè‡³å°‘ç¼ºå¤§éƒ¨åˆ†ï¼‰")
    if not _has_any(val, lvl_words): reasons.append("ä»·å€¼è§‚æœªè§ç­‰çº§è¯")
    cre = item.get("åˆ›é€ åŠ›","")
    dims8 = ["æµç•…æ€§","æ–°é¢–æ€§","çµæ´»æ€§","å¯è¡Œæ€§","é—®é¢˜å‘ç°","é—®é¢˜åˆ†æ","æå‡ºæ–¹æ¡ˆ","æ”¹å–„æ–¹æ¡ˆ"]
    if not _has_any(cre, dims8): reasons.append("åˆ›é€ åŠ›æœªè§å…«ç»´æ˜¾å¼åè¯ï¼ˆè‡³å°‘ç¼ºå¤§éƒ¨åˆ†ï¼‰")
    if "é›·è¾¾" not in cre and "æ€»ç»“" not in cre: reasons.append("åˆ›é€ åŠ›æœªè§é›·è¾¾æ€»ç»“æç¤ºè¯")
    psy = item.get("å¿ƒç†å¥åº·","")
    psy_kws = ["ç»¼åˆå¿ƒç†çŠ¶å†µ","å¹¸ç¦æŒ‡æ•°","æŠ‘éƒé£é™©","ç„¦è™‘é£é™©","ä¿¡æ¯ä¸è¶³æˆ–æœªè§æ˜¾è‘—ç—‡çŠ¶","èƒŒæ™¯","åº”å¯¹","æ”¯æŒ","å®¶åº­","åŒä¼´","è€å¸ˆ"]
    if not _has_any(psy, psy_kws): reasons.append("å¿ƒç†å¥åº·æœªè§æ ¸å¿ƒæ§½ä½å…³é”®è¯")
    ok = len(reasons) == 0
    return ok, reasons

# ================== åä½œåŸºçŸ³ï¼šç™½æ¿ä¸è®¨è®ºï¼ˆæ”¯æŒIOæ—¥å¿—ï¼‰ ==================
REQUIRED_KEYS = ["id","å§“å","å¹´é¾„","æ“…é•¿ç§‘ç›®","è–„å¼±ç§‘ç›®","å¹´çº§","äººæ ¼","ç¤¾äº¤å…³ç³»",
                 "å­¦æœ¯æ°´å¹³","æ€§åˆ«","å‘å±•é˜¶æ®µ","ä»£ç†å","ä»·å€¼è§‚","åˆ›é€ åŠ›","å¿ƒç†å¥åº·"]

class Whiteboard:
    def __init__(self, sid: int, sampling_hint: Optional[Dict[str,Any]] = None):
        self.facts: Dict[str, Any] = {"id": sid}
        if sampling_hint:
            self.facts["_é‡‡æ ·çº¦æŸ"] = sampling_hint
        self.discussion: List[Dict[str, str]] = []

    def read(self) -> Dict[str, Any]: return deepcopy(self.facts)
    def write(self, patch: Dict[str, Any]):
        for k,v in patch.items():
            self.facts[k] = v

    def log(self, speaker: str, content: str):
        # speaker ä¾‹ï¼š å­¦ä¸šç”»åƒâ†’prompt / å­¦ä¸šç”»åƒâ†output / Validator(issues) ç­‰
        self.discussion.append({"speaker": speaker, "content": content})

    def serialize_for_agent(self) -> str:
        return json.dumps({"draft": self.facts, "discussion": self.discussion}, ensure_ascii=False)

# ================== åŸºç¡€æç¤ºè¯ï¼šç»Ÿä¸€åè®® ==================
AGENT_PREAMBLE = """ä½ æ˜¯ä¸€ä¸ªä¸å…¶ä»–æ™ºèƒ½ä½“åä½œçš„â€œå­¦ç”Ÿç”»åƒâ€ç”Ÿäº§æˆå‘˜ã€‚æˆ‘ä»¬ä½¿ç”¨â€œå…¬å…±ç™½æ¿â€å…±äº«è‰ç¨¿ä¸è®¨è®ºã€‚
è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š
- æ‰€æœ‰è¾“å‡ºå¿…é¡»æ˜¯ **åˆæ³• JSON å¯¹è±¡**ï¼Œä¸”åªåŒ…å«ä½ è´Ÿè´£çš„é”®ã€‚
- ä¸å¾—å¼•ç”¨æ¨¡æ¿å¥å¼ï¼›ç”¨è‡ªç„¶ä¸­æ–‡ï¼›é¿å…ç©ºè¯å¥—è¯ï¼›é¿å…ä¸ç™½æ¿è‰ç¨¿è‡ªç›¸çŸ›ç›¾ã€‚
- è‹¥è¢«è¦æ±‚ä¿®è®¢ï¼Œåªæ”¹ä½ è´Ÿè´£çš„é”®ï¼›ä¸ç•™ç©ºï¼›ä¿è¯ä¸å…¶å®ƒå­—æ®µé€»è¾‘ä¸€è‡´ã€‚
- å§“åç­‰ä¸­æ–‡ï¼›æ•°å­—ä¸ç™¾åˆ†ä½è¯·ç”¨ä¸­æ–‡è¯­å¢ƒä¹¦å†™ï¼ˆå¦‚â€œå‰10%â€ï¼‰ã€‚
- ä¸è¦è¾“å‡ºä»»ä½•å¤šä½™è¯´æ˜æ–‡å­—ã€‚åªè¾“å‡º JSONã€‚
- å¦‚ç™½æ¿ä¸­å­˜åœ¨â€œ_é‡‡æ ·çº¦æŸâ€ï¼Œè¯·å°½é‡æ»¡è¶³å…¶ä¸­çš„â€œå¹´çº§â€â€œæ€§åˆ«â€â€œä¼˜åŠ¿å­¦ç§‘åå‘â€è¦æ±‚ï¼ˆè‹¥ä¸äº‹å®ä¸ç¬¦ï¼Œåº”ä»¥è‡ªç„¶ä¸€è‡´æ€§ä¸ºä¼˜å…ˆï¼‰ã€‚
"""

RESP_FIELDS = {
    "å­¦ç±ä¸å‘å±•é˜¶æ®µ": ["å§“å","å¹´é¾„","æ€§åˆ«","å¹´çº§","å‘å±•é˜¶æ®µ","ä»£ç†å"],
    "å­¦ä¸šç”»åƒ": ["æ“…é•¿ç§‘ç›®","è–„å¼±ç§‘ç›®","å­¦æœ¯æ°´å¹³"],
    "äººæ ¼ä¸ä»·å€¼è§‚": ["äººæ ¼","ä»·å€¼è§‚"],
    "ç¤¾äº¤ä¸åˆ›é€ åŠ›": ["ç¤¾äº¤å…³ç³»","åˆ›é€ åŠ›"],
    "èº«å¿ƒå¥åº·": ["å¿ƒç†å¥åº·"]
}

# ================== å„ Agentï¼ˆåŠ å…¥é‡‡æ ·çº¦æŸæç¤º + å¤šéŸ³èŠ‚ä»£ç†åç¤ºä¾‹ + IOæ—¥å¿—ï¼‰ ==================
def _pack_prompt(instruction: str, wb: Whiteboard) -> str:
    return f"ã€INSTRUCTIONã€‘\n{instruction}\n\nã€WHITEBOARDã€‘\n{wb.serialize_for_agent()}"

def agent_scholar(wb: Whiteboard, seed: str, mode: str="propose") -> Dict[str,Any]:
    sampling = wb.read().get("_é‡‡æ ·çº¦æŸ", {})
    hint = ""
    if sampling:
        hint = f"\né‡‡æ ·çº¦æŸï¼ˆå°½é‡éµå¾ªï¼‰ï¼šå¹´çº§={sampling.get('å¹´çº§','æœªæŒ‡å®š')}ï¼Œæ€§åˆ«={sampling.get('æ€§åˆ«','æœªæŒ‡å®š')}ã€‚"
    instruction = f"""{AGENT_PREAMBLE}{hint}
ä½ è´Ÿè´£é”®ï¼š{RESP_FIELDS["å­¦ç±ä¸å‘å±•é˜¶æ®µ"]}
ä»»åŠ¡æ¨¡å¼ï¼š{mode}
å¤šæ ·æ€§ç§å­ï¼š{seed}

ç”Ÿæˆä¸çº¦æŸï¼ˆå¿…é¡»ï¼‰ï¼š
- å¹´é¾„ 6~18ï¼›å¹´çº§ä¸å¹´é¾„åŒ¹é…ï¼ˆå…è®¸Â±1å¹´è·³çº§/ç•™çº§ä½†éœ€ä¸å…¶ä»–æ®µè½ä¸€è‡´ï¼‰ï¼›
- å‘å±•é˜¶æ®µå¯¹è±¡å¿…é¡»å«ä¸‰é”®ï¼šçš®äºšæ°è®¤çŸ¥å‘å±•é˜¶æ®µã€åŸƒé‡Œå…‹æ£®å¿ƒç†ç¤¾ä¼šå‘å±•é˜¶æ®µã€ç§‘å°”ä¼¯æ ¼é“å¾·å‘å±•é˜¶æ®µï¼›
- ä»£ç†åæ ¼å¼ï¼ˆ**å¤šéŸ³èŠ‚æ”¯æŒ**ï¼‰ï¼šå§“ 1~2 éŸ³èŠ‚ã€å 1~3 éŸ³èŠ‚ï¼›æ¯ä¸ªéŸ³èŠ‚ä¸ºâ€œæ‹¼éŸ³å°å†™+å£°è°ƒæ•°å­—(1-5)â€ï¼›å§“ä¸åä¹‹é—´ç”¨ä¸‹åˆ’çº¿ï¼›ç¤ºä¾‹ï¼š
  - å•å§“å•åï¼šzhang1_shuang3
  - å•å§“åŒåï¼šli1_huan4ying1
  - å¤å§“åŒåï¼šou3yang2_ming2hao3
ä»…è¾“å‡º JSONã€‚
"""
    messages = [
        {"role":"developer","content":instruction},
        {"role":"user","content":f"å…¬å…±ç™½æ¿ï¼š\n{wb.serialize_for_agent()}\nè¯·ä»…è¾“å‡ºä½ è´Ÿè´£çš„ JSONã€‚"}
    ]
    wb.log("å­¦ç±ä¸å‘å±•é˜¶æ®µâ†’prompt", _pack_prompt(instruction, wb))
    out = call_llm(messages, max_tokens=700, temperature=0.98)
    wb.log("å­¦ç±ä¸å‘å±•é˜¶æ®µâ†output", out)
    return try_json(out)

def agent_academic(wb: Whiteboard, seed: str, mode: str="propose") -> Dict[str,Any]:
    sampling = wb.read().get("_é‡‡æ ·çº¦æŸ", {})
    prefer = sampling.get("ä¼˜åŠ¿å­¦ç§‘åå‘")
    prefer_str = f"è¯·ä¼˜å…ˆä½¿â€œæ“…é•¿ç§‘ç›®â€è¦†ç›–è¯¥ç°‡ä¸­çš„è‡³å°‘1é—¨ï¼š{prefer}ã€‚" if prefer else ""
    instruction = f"""{AGENT_PREAMBLE}
ä½ è´Ÿè´£é”®ï¼š{RESP_FIELDS["å­¦ä¸šç”»åƒ"]}
ä»»åŠ¡æ¨¡å¼ï¼š{mode}
å¤šæ ·æ€§ç§å­ï¼š{seed}

è¦æ±‚ï¼ˆå¿…é¡»ï¼‰ï¼š
- â€œæ“…é•¿ç§‘ç›®â€ä¸â€œè–„å¼±ç§‘ç›®â€å‡ä¸ºéç©ºæ•°ç»„ï¼Œä¸”ä¸¤è€…**é›†åˆä¸ç›¸äº¤**ï¼›
- â€œå­¦æœ¯æ°´å¹³â€**ä¸¥æ ¼å››é€‰ä¸€ï¼Œä¸”å­—ç¬¦ä¸²å¿…é¡»å®Œå…¨ç­‰äºä»¥ä¸‹ä¹‹ä¸€**ï¼š
  1) "é«˜ï¼šæˆç»©å…¨æ ¡æ’åå‰10%"
  2) "ä¸­ï¼šæˆç»©å…¨æ ¡æ’åå‰10%è‡³30%"
  3) "ä½ï¼šæˆç»©å…¨æ ¡æ’åå‰30%è‡³50%"
  4) "å·®ï¼šæˆç»©å…¨æ ¡æ’åå50%"
- {prefer_str}
ä»…è¾“å‡º JSONï¼ˆåªå«â€œæ“…é•¿ç§‘ç›®â€â€œè–„å¼±ç§‘ç›®â€â€œå­¦æœ¯æ°´å¹³â€ä¸‰ä¸ªé”®ï¼‰ã€‚
"""
    messages = [
        {"role":"developer","content":instruction},
        {"role":"user","content":f"å…¬å…±ç™½æ¿ï¼š\n{wb.serialize_for_agent()}\nè¯·ä»…è¾“å‡ºä½ è´Ÿè´£çš„ JSONã€‚"}
    ]
    wb.log("å­¦ä¸šç”»åƒâ†’prompt", _pack_prompt(instruction, wb))
    out = call_llm(messages, max_tokens=600, temperature=0.9)
    wb.log("å­¦ä¸šç”»åƒâ†output", out)
    data = try_json(out)
    if isinstance(data, dict):
        lvl = data.get("å­¦æœ¯æ°´å¹³")
        if isinstance(lvl, str):
            for k, v in LEVEL_SET_STRICT.items():
                if lvl.startswith(k) or k in lvl:
                    data["å­¦æœ¯æ°´å¹³"] = v; break
    return data if isinstance(data, dict) else {}

def agent_values(wb: Whiteboard, seed: str, mode: str="propose") -> Dict[str,Any]:
    instruction = f"""{AGENT_PREAMBLE}
ä½ è´Ÿè´£é”®ï¼š{RESP_FIELDS["äººæ ¼ä¸ä»·å€¼è§‚"]}
ä»»åŠ¡æ¨¡å¼ï¼š{mode}
å¤šæ ·æ€§ç§å­ï¼š{seed}

è¾“å‡ºä½“è£ï¼ˆå¼ºçº¦æŸï¼‰ï¼šå•æ®µè¿ç»­è‡ªç„¶è¯­è¨€ï¼›**è¦†ç›–ä¸ƒç»´å¹¶æœ‰ç­‰çº§è¯**ï¼ˆé“å¾·ä¿®å…»ã€èº«å¿ƒå¥åº·ã€æ³•æ²»æ„è¯†ã€ç¤¾ä¼šè´£ä»»ã€æ”¿æ²»è®¤åŒã€æ–‡åŒ–ç´ å…»ã€å®¶åº­è§‚å¿µï¼‰ï¼›ç»™å‡ºèƒŒæ™¯åŒ–ä¾æ®ã€‚ä»…è¾“å‡º JSONã€‚
"""
    messages = [
        {"role":"developer","content":instruction},
        {"role":"user","content":f"å…¬å…±ç™½æ¿ï¼š\n{wb.serialize_for_agent()}\nè¯·ä»…è¾“å‡ºä½ è´Ÿè´£çš„ JSONã€‚"}
    ]
    wb.log("äººæ ¼ä¸ä»·å€¼è§‚â†’prompt", _pack_prompt(instruction, wb))
    out = call_llm(messages, max_tokens=900, temperature=1.0)
    wb.log("äººæ ¼ä¸ä»·å€¼è§‚â†output", out)
    return try_json(out)

def agent_social_creative(wb: Whiteboard, seed: str, mode: str="propose") -> Dict[str,Any]:
    instruction = f"""{AGENT_PREAMBLE}
ä½ è´Ÿè´£é”®ï¼š{RESP_FIELDS["ç¤¾äº¤ä¸åˆ›é€ åŠ›"]}
ä»»åŠ¡æ¨¡å¼ï¼š{mode}
å¤šæ ·æ€§ç§å­ï¼š{seed}

ç¤¾äº¤å…³ç³»ï¼šå•æ®µï¼ˆ160~260å­—ï¼‰ï¼ŒèƒŒæ™¯â†’å…³é”®äº‹ä»¶â†’å½±å“ï¼›ä¸å¾—æ¢è¡Œ/æ¡åˆ—ã€‚
åˆ›é€ åŠ›ï¼šå•æ®µï¼›**å…«ç»´ï¼ˆæµç•…æ€§/æ–°é¢–æ€§/çµæ´»æ€§/å¯è¡Œæ€§/é—®é¢˜å‘ç°/é—®é¢˜åˆ†æ/æå‡ºæ–¹æ¡ˆ/æ”¹å–„æ–¹æ¡ˆ å„æœ‰ç­‰çº§è¯ï¼‰+ é›·è¾¾æ€»ç»“**ï¼›å…«ç»´ä¸å¾—å…¨åŒæ¡£ï¼›è‹¥â€œå¯è¡Œæ€§â€è¾ƒä½/ä½ï¼Œåˆ™â€œæå‡ºæ–¹æ¡ˆâ€ä¸é«˜äºä¸­ç­‰ã€‚
ä»…è¾“å‡º JSONã€‚
"""
    messages = [
        {"role":"developer","content":instruction},
        {"role":"user","content":f"å…¬å…±ç™½æ¿ï¼š\n{wb.serialize_for_agent()}\nè¯·ä»…è¾“å‡ºä½ è´Ÿè´£çš„ JSONã€‚"}
    ]
    wb.log("ç¤¾äº¤ä¸åˆ›é€ åŠ›â†’prompt", _pack_prompt(instruction, wb))
    out = call_llm(messages, max_tokens=1100, temperature=1.02)
    wb.log("ç¤¾äº¤ä¸åˆ›é€ åŠ›â†output", out)
    return try_json(out)

def agent_health(wb: Whiteboard, seed: str, mode: str="propose") -> Dict[str,Any]:
    instruction = f"""{AGENT_PREAMBLE}
ä½ è´Ÿè´£é”®ï¼š{RESP_FIELDS["èº«å¿ƒå¥åº·"]}
ä»»åŠ¡æ¨¡å¼ï¼š{mode}
å¤šæ ·æ€§ç§å­ï¼š{seed}

å¿ƒç†å¥åº·ï¼šå•æ®µï¼›ä¾æ¬¡å†…åµŒ æ¦‚è¿°â†’æ€§æ ¼ç‰¹å¾(â‰¥2)â†’ç»¼åˆå¿ƒç†çŠ¶å†µ/å¹¸ç¦æŒ‡æ•°/æŠ‘éƒé£é™©/ç„¦è™‘é£é™©â†’å¿ƒç†ç–¾ç—…ï¼ˆå¦‚æ— å†™â€œä¿¡æ¯ä¸è¶³æˆ–æœªè§æ˜¾è‘—ç—‡çŠ¶â€ï¼‰â†’èƒŒæ™¯æ•…äº‹â†’æ”¯æ’‘ä¸åº”å¯¹ï¼›éè¯Šæ–­åŒ–ï¼›ä¸ä»·å€¼è§‚â€œèº«å¿ƒå¥åº·â€ä¸€è‡´ã€‚
ä»…è¾“å‡º JSONã€‚
"""
    messages = [
        {"role":"developer","content":instruction},
        {"role":"user","content":f"å…¬å…±ç™½æ¿ï¼š\n{wb.serialize_for_agent()}\nè¯·ä»…è¾“å‡ºä½ è´Ÿè´£çš„ JSONã€‚"}
    ]
    wb.log("èº«å¿ƒå¥åº·â†’prompt", _pack_prompt(instruction, wb))
    out = call_llm(messages, max_tokens=1100, temperature=0.96)
    wb.log("èº«å¿ƒå¥åº·â†output", out)
    return try_json(out)

def agent_validator(wb: Whiteboard, seed: str) -> Dict[str, Any]:
    instruction = f"""ä½ æ˜¯â€œValidatorâ€æ™ºèƒ½ä½“ã€‚è¯·ä¸¥æ ¼å®¡æ ¡å¹¶ç»™å‡º**ç»“æ„åŒ–ä¿®è®¢ä»»åŠ¡**ã€‚
{AGENT_PREAMBLE}
ä½ åªè¾“å‡º JSONï¼Œé”®ä¸º issues ä¸ final_readyã€‚ä¸è¦è¾“å‡ºå¤šä½™æ–‡å­—ã€‚
"""
    rules = f"""è§„åˆ™å‚è€ƒï¼ˆå¿…é¡»ï¼‰ï¼š
- R1 å¹´é¾„â†”å¹´çº§å¸¸æ¨¡ï¼ˆå…è®¸Â±1å¹´ï¼‰ã€‚
- R2 å‘å±•é˜¶æ®µä¸å¹´é¾„ä¸€è‡´æ€§ã€‚
- R3 ç§‘ç›®é›†åˆä¸äº¤å‰ã€ä¸”å‡éç©ºã€‚
- R3b å­¦æœ¯æ°´å¹³**ä¸¥æ ¼å››é€‰ä¸€**ï¼š{sorted(list(STRICT_ALLOWED_STRINGS))}
- R4 åˆ›é€ åŠ›å…«ç»´æœ‰èµ·ä¼ï¼›è‹¥â€œå¯è¡Œæ€§â€è¾ƒä½/ä½â†’â€œæå‡ºæ–¹æ¡ˆâ€â‰¤ä¸­ç­‰ã€‚
- R5 ä»·å€¼è§‚ç§¯æç¨³å¥ â†” å¿ƒç†æ®µè½ä¸å¾—å‡ºç°é‡åº¦ä¸´åºŠæœ¯è¯­/ä¸¥é‡åŠŸèƒ½å—æŸã€‚
- R6 ä»£ç†åæ­£åˆ™ï¼š{AGENT_ID_REGEX}
- R7 å¿…å¡«é”®ä¸å¯ä¸ºç©ºã€‚
- R8~R14ï¼šæ®µè½ä½“è£ä¸ç»“æ„ä½ç‚¹å®Œæ•´æ€§ï¼ˆä¸ƒç»´ä»·å€¼è§‚ã€å…«ç»´åˆ›é€ åŠ›+é›·è¾¾ã€å¿ƒç†å¥åº·å…³é”®æ§½ä½ä¸éè¯Šæ–­åŒ–ï¼‰ã€‚
- R15 å­¦æœ¯æ°´å¹³ä¸åœ¨é›†åˆâ†’è¦æ±‚å­¦ä¸šç”»åƒé‡å†™ä¸ºå››é€‰ä¸€å›ºå®šæ–‡æ¡ˆã€‚
è¾“å‡ºï¼šissues: [{{code, desc, owner, fields, hint}}], final_ready: bool
"""
    messages = [
        {"role":"developer","content":instruction},
        {"role":"user","content":f"å…¬å…±ç™½æ¿ï¼š\n{wb.serialize_for_agent()}\n{rules}\nè¯·è¾“å‡º JSONã€‚"}
    ]
    wb.log("Validatorâ†’prompt", _pack_prompt(instruction + "\n\n" + rules, wb))
    out = call_llm(messages, max_tokens=1100, temperature=0.2)
    wb.log("Validatorâ†output", out)
    data = try_json(out)
    # æœ¬åœ°å…œåº•ï¼ˆå­¦æœ¯æ°´å¹³ã€ä»£ç†åï¼‰
    try:
        lvl = wb.read().get("å­¦æœ¯æ°´å¹³", "")
        if lvl not in STRICT_ALLOWED_STRINGS:
            issues = data.get("issues", []) if isinstance(data, dict) else []
            issues.append({
                "code":"R3b",
                "desc":"å­¦æœ¯æ°´å¹³æœªä¸¥æ ¼åŒ¹é…å…è®¸é›†åˆã€‚",
                "owner":"å­¦ä¸šç”»åƒ",
                "fields":["å­¦æœ¯æ°´å¹³"],
                "hint":"æ›¿æ¢ä¸ºå›ºå®šæ–‡æ¡ˆä¹‹ä¸€ï¼š'é«˜ï¼šæˆç»©å…¨æ ¡æ’åå‰10%' / 'ä¸­ï¼šæˆç»©å…¨æ ¡æ’åå‰10%è‡³30%' / 'ä½ï¼šæˆç»©å…¨æ ¡æ’åå‰30%è‡³50%' / 'å·®ï¼šæˆç»©å…¨æ ¡æ’åå50%'"})
            data = {"issues": issues, "final_ready": False}
        agent_id = wb.read().get("ä»£ç†å", "")
        if not re.match(AGENT_ID_REGEX, str(agent_id)):
            issues = data.get("issues", []) if isinstance(data, dict) else []
            issues.append({
                "code":"R6",
                "desc":"ä»£ç†åä¸åˆè§„ï¼ˆåº”ä¸ºå¤šéŸ³èŠ‚æ‹¼éŸ³+å£°è°ƒæ•°å­—ï¼Œå§“1-2èŠ‚ï¼Œå1-3èŠ‚ï¼Œå§“ä¸åç”¨ä¸‹åˆ’çº¿åˆ†éš”ï¼‰ã€‚",
                "owner":"å­¦ç±ä¸å‘å±•é˜¶æ®µ",
                "fields":["ä»£ç†å"],
                "hint":"ç¤ºä¾‹ï¼šzhang1_shuang3 / li1_huan4ying1 / ou3yang2_ming2hao3"})
            data = {"issues": issues, "final_ready": False}
    except Exception:
        pass
    # è®°å½• issues JSONï¼ˆä¾¿äºUIè§£æï¼‰
    try:
        wb.log("Validator(issues)", json.dumps(data.get("issues", []), ensure_ascii=False))
    except Exception:
        wb.log("Validator(issues)", "[]")
    return data if data else {"issues":[{"code":"SYS","desc":"è§£æå¤±è´¥ï¼Œè¯·å„Agentè‡ªæ£€å¹¶é‡è¿°å…¶è´Ÿè´£å­—æ®µã€‚","owner":"å­¦ç±ä¸å‘å±•é˜¶æ®µ","fields":["å§“å"],"hint":"é‡æ–°å®Œæ•´ç»™å‡ºã€‚"}],"final_ready":False}

# ================== Orchestrator ==================
class Orchestrator:
    def __init__(self, max_rounds:int=3):
        self.max_rounds = max_rounds
        self.used_names: set = set()

    def _seed(self) -> str:
        return f"SEED-{random.randrange(10**16,10**17-1)}"

    def _merge_and_log(self, wb: Whiteboard, patch: Dict[str, Any], agent_name: str):
        wb.write(patch)
        wb.log(agent_name+"(åˆå¹¶)", json.dumps(patch, ensure_ascii=False))

    def run_one(self, sid: int, sampling_hint: Optional[Dict[str,Any]] = None) -> Tuple[Dict[str, Any], List[Dict[str,str]]]:
        wb = Whiteboard(sid, sampling_hint=sampling_hint)
        wb.log("System", f"ä»¥ä¸‹å§“åå·²è¢«ä½¿ç”¨ï¼ˆè¯·é¿å…é‡å¤ï¼‰ï¼š{list(self.used_names)}")
        seed = self._seed()

        self._merge_and_log(wb, agent_scholar(wb, seed, "propose"), "å­¦ç±ä¸å‘å±•é˜¶æ®µ")
        name_now = wb.read().get("å§“å")
        if name_now: self.used_names.add(name_now)

        self._merge_and_log(wb, agent_academic(wb, seed, "propose"), "å­¦ä¸šç”»åƒ")
        self._merge_and_log(wb, agent_values(wb, seed, "propose"), "äººæ ¼ä¸ä»·å€¼è§‚")
        self._merge_and_log(wb, agent_social_creative(wb, seed, "propose"), "ç¤¾äº¤ä¸åˆ›é€ åŠ›")
        self._merge_and_log(wb, agent_health(wb, seed, "propose"), "èº«å¿ƒå¥åº·")

        for r in range(1, self.max_rounds+1):
            v = agent_validator(wb, self._seed())
            issues = v.get("issues", [])
            final_ready = bool(v.get("final_ready", False))
            if final_ready and not issues:
                wb.log("Orchestrator", f"ç¬¬{r}è½®ï¼šValidatoré€šè¿‡âœ… æ— éœ€ç»§ç»­ä¿®è®¢ã€‚")
                break
            wb.log("Orchestrator", f"ç¬¬{r}è½®ï¼šæ”¶åˆ° {len(issues)} ä¸ªä¿®è®¢ä»»åŠ¡ã€‚")
            owners = {
                "å­¦ç±ä¸å‘å±•é˜¶æ®µ": agent_scholar,
                "å­¦ä¸šç”»åƒ": agent_academic,
                "äººæ ¼ä¸ä»·å€¼è§‚": agent_values,
                "ç¤¾äº¤ä¸åˆ›é€ åŠ›": agent_social_creative,
                "èº«å¿ƒå¥åº·": agent_health
            }
            wb.log("Validator(issues)", json.dumps(issues, ensure_ascii=False))
            touched = set()
            for it in issues:
                owner = it.get("owner")
                if owner in owners and owner not in touched:
                    patched = owners[owner](wb, self._seed(), "revise")
                    self._merge_and_log(wb, patched, owner+"(revise)")
                    touched.add(owner)

        final = wb.read()
        missing = [k for k in REQUIRED_KEYS if not non_empty(final.get(k))]
        if missing:
            wb.log("Orchestrator", f"æœ€ç»ˆè¡¥é½ï¼šç¼ºå¤± {missing}")
            for k in missing:
                owner = next((owner for owner,keys in RESP_FIELDS.items() if k in keys), None)
                if owner == "å­¦ç±ä¸å‘å±•é˜¶æ®µ":
                    self._merge_and_log(wb, agent_scholar(wb, self._seed(), "revise"), "å­¦ç±ä¸å‘å±•é˜¶æ®µ(revise-final)")
                elif owner == "å­¦ä¸šç”»åƒ":
                    self._merge_and_log(wb, agent_academic(wb, self._seed(), "revise"), "å­¦ä¸šç”»åƒ(revise-final)")
                elif owner == "äººæ ¼ä¸ä»·å€¼è§‚":
                    self._merge_and_log(wb, agent_values(wb, self._seed(), "revise"), "äººæ ¼ä¸ä»·å€¼è§‚(revise-final)")
                elif owner == "ç¤¾äº¤ä¸åˆ›é€ åŠ›":
                    self._merge_and_log(wb, agent_social_creative(wb, self._seed(), "revise"), "ç¤¾äº¤ä¸åˆ›é€ åŠ›(revise-final)")
                elif owner == "èº«å¿ƒå¥åº·":
                    self._merge_and_log(wb, agent_health(wb, self._seed(), "revise"), "èº«å¿ƒå¥åº·(revise-final)")
            final = wb.read()

        for k in REQUIRED_KEYS:
            if not non_empty(final.get(k)):
                raise RuntimeError(f"å­—æ®µä»ä¸ºç©ºï¼š{k}")

        lvl = final.get("å­¦æœ¯æ°´å¹³", "")
        if lvl not in STRICT_ALLOWED_STRINGS:
            raise RuntimeError("å­¦æœ¯æ°´å¹³ä¸ç¬¦åˆä¸¥æ ¼å››é€‰ä¸€æ ‡å‡†ï¼Œè¯·é‡è¯•ã€‚")

        final.pop("_é‡‡æ ·çº¦æŸ", None)
        return final, wb.discussion

# ================== QuotaSchedulerï¼šç”Ÿæˆç›®æ ‡é…é¢æ§½ä½ ==================
def _default_quota(n_total: int) -> List[Dict[str,Any]]:
    slots = []
    triplets = [(g,s,c) for g in GRADES for s in GENDERS for c in SUBJ_CLUSTERS.keys()]
    for i in range(n_total):
        g, s, c = triplets[i % len(triplets)]
        slots.append({"å¹´çº§": g, "æ€§åˆ«": s, "ä¼˜åŠ¿å­¦ç§‘åå‘": SUBJ_CLUSTERS[c]})
    random.shuffle(slots)
    return slots

class QuotaScheduler:
    def __init__(self, n_total: int, user_quota_json: Optional[str] = None):
        if user_quota_json:
            try:
                arr = json.loads(user_quota_json)
                assert isinstance(arr, list) and all(isinstance(x, dict) for x in arr)
                self.slots = arr
            except Exception:
                self.slots = _default_quota(n_total)
        else:
            self.slots = _default_quota(n_total)
        self.idx = 0
        self.total = n_total
    def has_next(self) -> bool:
        return self.idx < self.total
    def next_slot(self) -> Dict[str,Any]:
        if not self.has_next(): return {}
        slot = self.slots[self.idx]; self.idx += 1; return slot

# ================== æœ¬åœ°è½ç›˜ï¼ˆè‡ªåŠ¨ JSONLï¼‰ ==================
def _ensure_dirs():
    base = os.path.join(os.getcwd(), "output")
    if not os.path.exists(base): os.makedirs(base, exist_ok=True)
    return base

def _init_run_dir():
    base = _ensure_dirs()
    run_id = f"run_{int(time.time())}"
    run_dir = os.path.join(base, run_id)
    os.makedirs(run_dir, exist_ok=True)
    return run_id, run_dir

def _chunk_path(run_dir: str, chunk_no: int) -> str:
    return os.path.join(run_dir, f"students_chunk_{chunk_no}.jsonl")

def _append_record(run_dir: str, chunk_no: int, record: Dict[str, Any]):
    path = _chunk_path(run_dir, chunk_no)
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")

def _append_failure(run_dir: str, failure: Dict[str, Any]):
    path = os.path.join(run_dir, "failures.jsonl")
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(failure, ensure_ascii=False) + "\n")

def _count_lines(path: str) -> int:
    if not os.path.exists(path): return 0
    cnt = 0
    with open(path, "r", encoding="utf-8") as f:
        for _ in f: cnt += 1
    return cnt

def _recover_progress_from_disk(run_dir: str, chunk_size: int) -> Tuple[int,int,int]:
    files = sorted(glob.glob(os.path.join(run_dir, "students_chunk_*.jsonl")))
    if not files: return 1, 0, 1
    def _num(p):
        m = re.search(r"students_chunk_(\d+)\.jsonl$", p)
        return int(m.group(1)) if m else 0
    files.sort(key=_num)
    last = files[-1]; last_no = _num(last)
    done_in_last = _count_lines(last)
    chunk_idx = last_no; in_chunk_idx = done_in_last
    global_idx = (chunk_idx-1)*chunk_size + in_chunk_idx + 1
    if in_chunk_idx >= chunk_size: chunk_idx += 1; in_chunk_idx = 0
    return chunk_idx, in_chunk_idx, global_idx

def _load_chunk_preview(run_dir: str, chunk_idx: int, max_items: int = 6) -> List[Dict[str, Any]]:
    path = _chunk_path(run_dir, chunk_idx)
    if not os.path.exists(path): return []
    lines = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line: continue
            try: lines.append(json.loads(line))
            except: pass
    return lines[-max_items:]

# ================== UI ==================
st.set_page_config(page_title="å¤šæ™ºèƒ½ä½“ç”»åƒç”Ÿæˆï¼ˆå¸¦åœ¨çº¿å‰ç½®æ§åˆ¶+äº¤äº’æ§åˆ¶å°ï¼‰", page_icon="ğŸ§©", layout="wide")
st.title("ğŸ§© å­¦ç”Ÿç”»åƒ Â· å¤šæ™ºèƒ½ä½“å®æ—¶åä½œï¼ˆåœ¨çº¿å‰ç½®æ§åˆ¶ + äº¤äº’æ§åˆ¶å°ï¼‰")

with st.sidebar:
    st.subheader("åœ¨çº¿å‰ç½®æ§åˆ¶")
    simhash_th = st.number_input("ç›¸ä¼¼åº¦é˜ˆï¼ˆSimHashæ±‰æ˜è·ç¦»ï¼Œâ‰¤è§†ä¸ºè¿‡è¿‘éœ€é‡ç”Ÿï¼‰", 0, 16, SIMHASH_HAMMING_THRESHOLD_DEFAULT)
    user_quota_json = st.text_area("è‡ªå®šä¹‰é…é¢JSONï¼ˆå¯é€‰ï¼‰", placeholder='[{"å¹´çº§":"åˆä¸€","æ€§åˆ«":"å¥³","ä¼˜åŠ¿å­¦ç§‘åå‘":["è‹±è¯­","ç”Ÿç‰©"]}]')
    show_console = st.toggle("æ˜¾ç¤ºäº¤äº’æ§åˆ¶å°ï¼ˆPrompt/Output/Issuesï¼‰", value=True)
    st.caption("ç•™ç©ºé…é¢åˆ™æŒ‰å¹´çº§Ã—æ€§åˆ«Ã—å­¦ç§‘ç°‡å‡è¡¡é»˜è®¤é…é¢ã€‚")

with st.expander("è¯´æ˜", expanded=False):
    st.markdown("""
- **é…é¢åˆ†æ¡¶è°ƒåº¦**ã€**è½»é‡è¿‡æ»¤**ã€**SimHash å»åŒè´¨åŒ–**ï¼›ä¸è¿‡å…³å³é‡é‡‡ï¼›  
- è‡ªåŠ¨è½ç›˜ï¼š`output/<run_id>/students_chunk_{i}.jsonl`ï¼›å¤±è´¥æ ·æœ¬ `failures.jsonl`ï¼›  
- å­¦æœ¯æ°´å¹³å››é€‰ä¸€ï¼ˆå›ºå®šæ–‡æ¡ˆï¼‰ï¼›ä»£ç†åï¼šå§“ 1â€“2 éŸ³èŠ‚ã€å 1â€“3 éŸ³èŠ‚ï¼Œæ¯èŠ‚â€œæ‹¼éŸ³+1~5 å£°è°ƒâ€ï¼Œä¸‹åˆ’çº¿åˆ†éš”ã€‚  
- æ–°å¢**äº¤äº’æ§åˆ¶å°**ï¼šé€æ­¥å±•ç¤ºæ¯ä¸ª Agent çš„ Prompt/Outputï¼Œä»¥åŠ Validator çš„ issuesï¼ˆè¡¨æ ¼ï¼‰ã€‚  
""")

left, right = st.columns([1,3])
with left:
    n = st.number_input("ç”Ÿæˆæ•°é‡ï¼ˆæ— é™åˆ¶ï¼‰", min_value=1, value=100, step=1)
    rounds = st.number_input("æœ€å¤§åå•†è½®æ•°ï¼ˆæ— é™åˆ¶ï¼‰", min_value=1, value=3, step=1)
    chunk_size = CHUNK_SIZE_DEFAULT
    start_btn = st.button("å¼€å§‹ç”Ÿæˆ", type="primary")
    pause_btn = st.button("æš‚åœç”Ÿæˆ â¸")
    resume_btn = st.button("ç»§ç»­ç”Ÿæˆ â–¶ï¸")

# ----------- çŠ¶æ€åˆå§‹åŒ– -----------
if "running" not in st.session_state: st.session_state.running = False
if "paused" not in st.session_state: st.session_state.paused = False
if "total_n" not in st.session_state: st.session_state.total_n = 0
if "max_rounds" not in st.session_state: st.session_state.max_rounds = 3
if "chunk_size" not in st.session_state: st.session_state.chunk_size = CHUNK_SIZE_DEFAULT
if "chunks_total" not in st.session_state: st.session_state.chunks_total = 0
if "chunk_idx" not in st.session_state: st.session_state.chunk_idx = 1
if "in_chunk_idx" not in st.session_state: st.session_state.in_chunk_idx = 0
if "global_idx" not in st.session_state: st.session_state.global_idx = 1
if "orch" not in st.session_state: st.session_state.orch = None
if "run_id" not in st.session_state: st.session_state.run_id = None
if "run_dir" not in st.session_state: st.session_state.run_dir = None
if "last_item" not in st.session_state: st.session_state.last_item = None
if "last_dialog" not in st.session_state: st.session_state.last_dialog = []
if "last_error" not in st.session_state: st.session_state.last_error = None
if "quota" not in st.session_state: st.session_state.quota = None
if "sim_gate" not in st.session_state: st.session_state.sim_gate = SimilarityGate(threshold=simhash_th)

# ----------- æ§åˆ¶æŒ‰é’® -----------
if start_btn:
    st.session_state.running = True
    st.session_state.paused = False
    st.session_state.total_n = int(n)
    st.session_state.max_rounds = int(rounds)
    st.session_state.chunk_size = int(chunk_size)
    st.session_state.chunks_total = math.ceil(st.session_state.total_n / st.session_state.chunk_size)
    st.session_state.run_id, st.session_state.run_dir = _init_run_dir()
    st.session_state.chunk_idx = 1
    st.session_state.in_chunk_idx = 0
    st.session_state.global_idx = 1
    st.session_state.orch = Orchestrator(max_rounds=st.session_state.max_rounds)
    st.session_state.last_item = None
    st.session_state.last_dialog = []
    st.session_state.last_error = None
    st.session_state.quota = QuotaScheduler(st.session_state.total_n, user_quota_json=user_quota_json)
    st.session_state.sim_gate = SimilarityGate(threshold=simhash_th)
    st.success(f"è¾“å‡ºç›®å½•ï¼š{st.session_state.run_dir}")
    _st_rerun()

if pause_btn and st.session_state.running:
    st.session_state.paused = True

if resume_btn and st.session_state.running:
    st.session_state.paused = False
    if st.session_state.run_dir:
        ck_idx, in_ck_idx, g_idx = _recover_progress_from_disk(st.session_state.run_dir, st.session_state.chunk_size)
        st.session_state.chunk_idx = ck_idx
        st.session_state.in_chunk_idx = in_ck_idx
        st.session_state.global_idx = g_idx
    _st_rerun()

# ----------- è¿›åº¦æ¡å®¹å™¨ -----------
chunk_prog_box = st.empty()
prog = st.empty()
status = st.empty()
preview_live = st.container()
console = st.container()
cards = st.container()

# ----------- ä¸»å¾ªç¯ -----------
if st.session_state.running:
    chunk_prog = (st.session_state.chunk_idx-1) / max(1, st.session_state.chunks_total)
    chunk_prog_box.progress(
        min(chunk_prog, 1.0),
        text=f"åˆ†ç‰‡è¿›åº¦ï¼šç¬¬ {st.session_state.chunk_idx}/{st.session_state.chunks_total} ç‰‡ï¼ˆæ¯ç‰‡ {st.session_state.chunk_size} æ¡ï¼‰ Â· è¾“å‡ºç›®å½•ï¼š{st.session_state.run_dir or 'ï¼ˆæœªåˆå§‹åŒ–ï¼‰'}"
    )
    if st.session_state.paused:
        status.warning(f"å·²æš‚åœï¼ˆå½“å‰ç‰‡å·²å®Œæˆ {st.session_state.in_chunk_idx}/{st.session_state.chunk_size} æ¡ï¼›ç»§ç»­åè‡ªåŠ¨ç»­å†™ï¼‰")
    else:
        current_chunk_total = min(st.session_state.chunk_size, st.session_state.total_n - (st.session_state.chunk_idx-1)*st.session_state.chunk_size)
        status.info(f"ç”Ÿæˆä¸­ï¼šå…¨å±€ç¬¬ {st.session_state.global_idx}/{st.session_state.total_n} æ¡ Â· å½“å‰ç‰‡ç¬¬ {st.session_state.in_chunk_idx+1}/{current_chunk_total} æ¡")

    current_chunk_total = min(st.session_state.chunk_size, st.session_state.total_n - (st.session_state.chunk_idx-1)*st.session_state.chunk_size)
    prog.progress(st.session_state.in_chunk_idx / max(1, current_chunk_total), text=f"å½“å‰ç‰‡è¿›åº¦ï¼š{st.session_state.in_chunk_idx}/{current_chunk_total}")

    # å³æ—¶é¢„è§ˆï¼ˆæœ¬æ¡ï¼‰
    with preview_live:
        st.subheader("ğŸ–¥ï¸ å³æ—¶é¢„è§ˆï¼ˆæœ¬æ¡ç”Ÿæˆçš„ç”»åƒï¼‰")
        if st.session_state.last_error: st.error(st.session_state.last_error)
        if st.session_state.last_item:
            with st.expander(f"{st.session_state.last_item.get('å§“å')} â€” {st.session_state.last_item.get('å¹´çº§')} Â· ä»£ç†åï¼š{st.session_state.last_item.get('ä»£ç†å')}", expanded=True):
                st.json(st.session_state.last_item, expanded=False)

    # äº¤äº’æ§åˆ¶å°ï¼ˆæœ¬æ¡ï¼‰
    if show_console and st.session_state.last_dialog:
        with console:
            st.subheader("ğŸ–§ äº¤äº’æ§åˆ¶å°ï¼ˆæœ¬æ¡ï¼‰")
            tabs = st.tabs(["å­¦ç±ä¸å‘å±•é˜¶æ®µ", "å­¦ä¸šç”»åƒ", "äººæ ¼ä¸ä»·å€¼è§‚", "ç¤¾äº¤ä¸åˆ›é€ åŠ›", "èº«å¿ƒå¥åº·", "Validator", "Whiteboard RAW"])

            # æŒ‰ Agent è¿‡æ»¤æ—¥å¿—çš„å°å·¥å…·
            def _show_logs(agent_key: str):
                logs = [m for m in st.session_state.last_dialog if m["speaker"].startswith(agent_key)]
                if not logs:
                    st.info("æš‚æ— æ—¥å¿—")
                else:
                    for m in logs[-12:]:
                        st.markdown(f"**{m['speaker']}**")
                        st.code(m["content"])

            with tabs[0]:
                _show_logs("å­¦ç±ä¸å‘å±•é˜¶æ®µ")
            with tabs[1]:
                _show_logs("å­¦ä¸šç”»åƒ")
            with tabs[2]:
                _show_logs("äººæ ¼ä¸ä»·å€¼è§‚")
            with tabs[3]:
                _show_logs("ç¤¾äº¤ä¸åˆ›é€ åŠ›")
            with tabs[4]:
                _show_logs("èº«å¿ƒå¥åº·")
            with tabs[5]:
                # å±•ç¤º Validator prompt/output ä¸ issues è¡¨
                _show_logs("Validator")
                # è§£ææœ€è¿‘ä¸€æ¬¡ issues JSON
                import pandas as pd
                issues_rows = []
                for m in reversed(st.session_state.last_dialog):
                    if m["speaker"] == "Validator(issues)":
                        try:
                            arr = json.loads(m["content"])
                            if isinstance(arr, list):
                                issues_rows = arr; break
                        except: pass
                if issues_rows:
                    df = pd.DataFrame(issues_rows)
                    st.dataframe(df, use_container_width=True)
                else:
                    st.info("æœªæ•è·åˆ°ç»“æ„åŒ– issuesã€‚")
            with tabs[6]:
                # å…¨é‡æ—¥å¿—ï¼ˆä¾¿äºæ’æŸ¥ï¼‰
                for m in st.session_state.last_dialog[-40:]:
                    st.markdown(f"**{m['speaker']}**")
                    st.code(m["content"])

    # ç‰‡å°¾é¢„è§ˆ
    with cards:
        st.subheader("ğŸ“‚ å½“å‰ç‰‡æœ«å°¾é¢„è§ˆï¼ˆæ¥è‡ªæœ¬åœ°æ–‡ä»¶ï¼‰")
        if st.session_state.run_dir:
            preview_items = _load_chunk_preview(st.session_state.run_dir, st.session_state.chunk_idx, max_items=6)
            if preview_items:
                start_idx = max(1, st.session_state.in_chunk_idx - len(preview_items) + 1)
                for idx, item in enumerate(preview_items, start=start_idx):
                    with st.expander(f"#{idx} â€” {item.get('å§“å')}ï¼ˆ{item.get('å¹´çº§')}ï¼‰ Â· ä»£ç†åï¼š{item.get('ä»£ç†å')}", expanded=False):
                        st.json(item, expanded=False)
            else:
                st.info("å½“å‰ç‰‡æš‚æ— å·²å†™å…¥è®°å½•ã€‚")

    # ç»“æŸ
    if st.session_state.global_idx > st.session_state.total_n or (st.session_state.quota and not st.session_state.quota.has_next()):
        prog.progress(1.0, text="å½“å‰ç‰‡è¿›åº¦ï¼šå®Œæˆ âœ…")
        chunk_prog_box.progress(1.0, text="åˆ†ç‰‡è¿›åº¦ï¼šå…¨éƒ¨å®Œæˆ âœ…")
        status.success(f"å…¨éƒ¨ç”Ÿæˆå®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{st.session_state.run_dir}")
        st.session_state.running = False

    # æ¨è¿›ä¸€ä¸ªæ§½ä½ï¼ˆæœªæš‚åœæ—¶ï¼‰
    elif not st.session_state.paused:
        slot = st.session_state.quota.next_slot() if st.session_state.quota else {}
        target_sid = st.session_state.global_idx
        orch: Orchestrator = st.session_state.orch
        accepted = False
        error_trace = None

        for attempt in range(1, MAX_RETRIES_PER_SLOT+1):
            try:
                item, dialog = orch.run_one(target_sid, sampling_hint=slot)

                # è½»é‡è¿‡æ»¤
                ok, reasons = _light_filter(item)
                if not ok:
                    error_trace = f"è½»é‡è¿‡æ»¤ä¸é€šè¿‡ï¼š{'; '.join(reasons)}"
                    raise RuntimeError(error_trace)

                # è‡ªç›¸ä¼¼åº¦é—¨æ§
                key_text = "ï½œ".join([
                    str(item.get("å¹´çº§","")), str(item.get("æ€§åˆ«","")),
                    " ".join(item.get("äººæ ¼",[]) if isinstance(item.get("äººæ ¼"), list) else [str(item.get("äººæ ¼",""))]),
                    str(item.get("ä»·å€¼è§‚","")), str(item.get("ç¤¾äº¤å…³ç³»","")),
                    str(item.get("åˆ›é€ åŠ›","")), str(item.get("å¿ƒç†å¥åº·",""))
                ])
                if st.session_state.sim_gate.too_similar(key_text):
                    error_trace = f"ä¸å·²æœ‰æ ·æœ¬è¿‡è¿‘ï¼ˆSimHashâ‰¤{st.session_state.sim_gate.threshold}ï¼‰"
                    raise RuntimeError(error_trace)

                # é€šè¿‡ï¼šå†™ç›˜ã€ç™»è®°ç›¸ä¼¼åº¦æ± ã€ç¼“å­˜ç•Œé¢
                _append_record(st.session_state.run_dir, st.session_state.chunk_idx, item)
                st.session_state.sim_gate.accept(key_text)

                st.session_state.in_chunk_idx += 1
                st.session_state.global_idx += 1
                st.session_state.last_item = item
                st.session_state.last_dialog = dialog
                st.session_state.last_error = None

                if st.session_state.in_chunk_idx >= st.session_state.chunk_size:
                    st.session_state.in_chunk_idx = 0
                    st.session_state.chunk_idx += 1

                accepted = True
                break

            except Exception as e:
                err_msg = f"æ§½ä½{slot} Â· å°è¯•{attempt}/{MAX_RETRIES_PER_SLOT}å¤±è´¥ï¼š{e}"
                st.session_state.last_error = err_msg
                if attempt == MAX_RETRIES_PER_SLOT:
                    _append_failure(st.session_state.run_dir, {"slot": slot, "sid": target_sid, "error": str(e)})
                    st.session_state.global_idx += 1

        if not accepted and error_trace:
            st.error(error_trace)

        _st_rerun()
